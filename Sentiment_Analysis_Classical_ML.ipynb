{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification on Sentihood data\n",
    "\n",
    "## Comparison of various classical ML text classification algorithms and different word vectors with word-sentiment based methods (Vader and SentiWordNet)\n",
    "\n",
    "## ML Classification Algorithms\n",
    "        1. Naive Bayes\n",
    "        2. Random Forest\n",
    "        3. SVM\n",
    "    \n",
    "## Word Vectors\n",
    "        1. TFIDF\n",
    "        2. Word2Vector\n",
    "        3. Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy import spatial\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "w2v_nlp = spacy.load('en_core_web_lg')\n",
    "glove_model_name=\"glove-wiki-gigaword-100\"\n",
    "glove_model = api.load(glove_model_name)\n",
    "\n",
    "tokenizer = Tokenizer(w2v_nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"{os.environ['HOME']}/data/SentimentAnalysis/\"\n",
    "\n",
    "label_map = {\n",
    "    \"Neutral\": 0,\n",
    "    \"Positive\":1,\n",
    "    \"Negative\":2,\n",
    "}\n",
    "\n",
    "\n",
    "def load_data(version):\n",
    "    \"\"\"\n",
    "    preprocess data and create dataframe\n",
    "    \"\"\"\n",
    "    data_file = os.path.join(data_dir, \"sentihood\", f\"sentihood-{version}.json\")\n",
    "    json_data = json.load(open(data_file))\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for jd in json_data:        \n",
    "        # Get the label\n",
    "        label = 0\n",
    "        for op in jd[\"opinions\"]:\n",
    "            if op[\"aspect\"] == \"general\":\n",
    "                sentiment = op[\"sentiment\"]\n",
    "                label = label_map[sentiment]\n",
    "\n",
    "        # Get the text on the side of the entity\n",
    "        text = jd[\"text\"]\n",
    "        target_entity = op[\"target_entity\"]\n",
    "        text = text.replace(target_entity, \"\")\n",
    "        data.append([text, target_entity, label])\n",
    "    \n",
    "    #Return data as dataframe\n",
    "    df = pd.DataFrame.from_records(data, columns=[\"text\", \"entity\", \"label\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_train, df_test = load_data(\"train\"), load_data(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = df_test\n",
    "\n",
    "####### Oversampling the negative cases\n",
    "\n",
    "n = 3 # no. of times to oversample negative sentiments\n",
    "df_test3 = df_test2.loc[df_test2[\"label\"]==2,:]\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    df_test4= df_test2.append(df_test3)\n",
    "\n",
    "\n",
    "####### Undersampling the neutral cases\n",
    "\n",
    "df_new = df_test4.loc[df_test4[\"label\"]==0,:]\n",
    "df_new_sel = pd.DataFrame()\n",
    "for i in range(len(df_new)):\n",
    "    if (i%2 == 0) or (i%2==1) :\n",
    "        df_new_sel= df_new_sel.append(df_new.loc[df_new.index ==i,:])\n",
    "            \n",
    "            \n",
    "df_test5= df_test4.drop(df_new_sel.index)          \n",
    "\n",
    "df_test = df_test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, y_train = df_train[\"text\"], df_train[\"label\"]\n",
    "test_texts, y_test = df_test[\"text\"], df_test[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment score using Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text     entity  label  \\\n",
      "1     All the neighborhoods around  are very nice ...  LOCATION1      1   \n",
      "2           Cheap is , LOCATION1, but not really cool  LOCATION2      2   \n",
      "3                                           Dont Try   LOCATION1      2   \n",
      "11    I live in  and would really recommend it or ...  LOCATION2      1   \n",
      "15    I only go to  to  IKEA - I find it depressin...  LOCATION1      2   \n",
      "\n",
      "                                              vdscore  vdcmpd  \n",
      "1   {'neg': 0.0, 'neu': 0.528, 'pos': 0.472, 'comp...     1.0  \n",
      "2   {'neg': 0.316, 'neu': 0.684, 'pos': 0.0, 'comp...     2.0  \n",
      "3   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...     0.0  \n",
      "11  {'neg': 0.0, 'neu': 0.798, 'pos': 0.202, 'comp...     1.0  \n",
      "15  {'neg': 0.191, 'neu': 0.809, 'pos': 0.0, 'comp...     2.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/exp/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ubuntu/anaconda3/envs/exp/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/ubuntu/anaconda3/envs/exp/lib/python3.7/site-packages/pandas/core/generic.py:6746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "df_test['vdscore'] = df_test['text'].apply(lambda x: sid.polarity_scores(x))\n",
    "df_test['vdcmpd'] = df_test['vdscore'].apply(lambda x: np.sign(x['compound']))\n",
    "df_test[\"vdcmpd\"].replace(-1, 2, inplace = True)\n",
    "print (df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[165 143  40]\n",
      " [ 69 285  14]\n",
      " [ 48  66 116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.47      0.52       348\n",
      "           1       0.58      0.77      0.66       368\n",
      "           2       0.68      0.50      0.58       230\n",
      "\n",
      "    accuracy                           0.60       946\n",
      "   macro avg       0.61      0.58      0.59       946\n",
      "weighted avg       0.61      0.60      0.59       946\n",
      "\n",
      "Accuracy: 0.5983086680761099\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(df_test[\"label\"], df_test[\"vdcmpd\"]))\n",
    "print (classification_report(df_test[\"label\"], df_test[\"vdcmpd\"]))\n",
    "print(\"Accuracy:\",accuracy_score(df_test[\"label\"], df_test[\"vdcmpd\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \"\"\"\n",
    "    Convert between the PennTreebank tags to simple Wordnet tags\n",
    "    \"\"\"\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment score using Sentiwordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def sentiment_sentiwordnet(text):\n",
    "    raw_sentences = sent_tokenize(text)\n",
    "    sentiment = 0\n",
    "    tokens_count = 0\n",
    "\n",
    "    for raw_sentence in raw_sentences:\n",
    "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
    "\n",
    "        for word, tag in tagged_sentence:\n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "                continue\n",
    "\n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            if not lemma:\n",
    "                continue\n",
    "\n",
    "            synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    "\n",
    "            synset = synsets[0]\n",
    "            swn_synset = swn.senti_synset(synset.name())\n",
    "            word_sent = swn_synset.pos_score() - swn_synset.neg_score()\n",
    "\n",
    "            if word_sent != 0:\n",
    "                sentiment += word_sent\n",
    "                tokens_count += 1\n",
    "\n",
    "    if tokens_count == 0:\n",
    "        return 0\n",
    "    sentiment = sentiment/tokens_count\n",
    "    if sentiment >= 0.01:\n",
    "        return 1\n",
    "    if sentiment <= -0.01:\n",
    "        return 2\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/exp/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_test['swscore'] = df_test['text'].apply(lambda x: sentiment_sentiwordnet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[121 128  99]\n",
      " [ 87 219  62]\n",
      " [ 38  70 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.35      0.41       348\n",
      "           1       0.53      0.60      0.56       368\n",
      "           2       0.43      0.53      0.48       230\n",
      "\n",
      "    accuracy                           0.49       946\n",
      "   macro avg       0.48      0.49      0.48       946\n",
      "weighted avg       0.49      0.49      0.48       946\n",
      "\n",
      "Accuracy: 0.4883720930232558\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(df_test[\"label\"], df_test[\"swscore\"]))\n",
    "print (classification_report(df_test[\"label\"], df_test[\"swscore\"]))\n",
    "print(\"Accuracy:\",accuracy_score(df_test[\"label\"], df_test[\"swscore\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text sentiment classification using word vectors\n",
    "\n",
    "## Load training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select NB or SVM classifier with tfidf\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),('clf', MultinomialNB())])\n",
    "#text_clf = Pipeline([('tfidf', TfidfVectorizer()),('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tfidf training and predictions\n",
    "text_clf.fit(train_texts, y_train)\n",
    "y_pred = text_clf.predict(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[347   1   0]\n",
      " [331  37   0]\n",
      " [222   8   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.56       348\n",
      "           1       0.80      0.10      0.18       368\n",
      "           2       0.00      0.00      0.00       230\n",
      "\n",
      "    accuracy                           0.41       946\n",
      "   macro avg       0.40      0.37      0.24       946\n",
      "weighted avg       0.45      0.41      0.27       946\n",
      "\n",
      "Accuracy: 0.4059196617336152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/exp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(y_test, y_pred))\n",
    "print (classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Word2Vec and Glove\n",
    "\n",
    "https://towardsdatascience.com/using-word2vec-to-analyze-news-headlines-and-predict-article-success-cdeda5f14751 \n",
    "\n",
    "\"Trained on enormous google news corpus\"\n",
    "\n",
    "Pretrained word2vec and glove models\n",
    "\n",
    "https://github.com/RaRe-Technologies/gensim-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data2Vector:\n",
    "    def __init__(self, vec_emb):\n",
    "        self.vec_emb = vec_emb\n",
    "        \n",
    "    def word_vector(self, word):\n",
    "        \n",
    "        if self.vec_emb == 'w2v':\n",
    "            return w2v_nlp(str(word)).vector\n",
    "        else:\n",
    "            if word in glove_model:\n",
    "                return glove_model[str(word)]\n",
    "            else:\n",
    "                return glove_model[\"unk\"]\n",
    "\n",
    "\n",
    "    def sent_vector(self, sent): \n",
    "        tokens = tokenizer(sent)\n",
    "        if len(tokens) == 0:\n",
    "            tokens = [\"unk\"]\n",
    "        sent_vectors = [self.word_vector(token) for token in tokens]\n",
    "        return np.average(np.array(sent_vectors), axis=0).tolist()\n",
    "      \n",
    "        \n",
    "    def data_vector(self, data):\n",
    "           \n",
    "        sent_vec = []\n",
    "        for i in range(len(data)):\n",
    "            sent_vec.append(self.sent_vector(data[i]))\n",
    "        return (sent_vec)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Select word embedding\n",
    "\n",
    "sel_vec_method = \"w2v\"\n",
    "#sel_vec_method = \"glove\"\n",
    "\n",
    "\n",
    "#Step 2: Select classification method\n",
    "\n",
    "clf = LinearSVC()\n",
    "#clf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert text to vectors\n",
    "dv = Data2Vector(sel_vec_method)\n",
    "\n",
    "train_texts_vec =dv.data_vector(list(train_texts))\n",
    "test_texts_vec =dv.data_vector(list(test_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training-Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20, n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using the training sets\n",
    "clf.fit(train_texts_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(test_texts_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[348   0   0]\n",
      " [368   0   0]\n",
      " [230   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54       348\n",
      "           1       0.00      0.00      0.00       368\n",
      "           2       0.00      0.00      0.00       230\n",
      "\n",
      "    accuracy                           0.37       946\n",
      "   macro avg       0.12      0.33      0.18       946\n",
      "weighted avg       0.14      0.37      0.20       946\n",
      "\n",
      "Accuracy: 0.3678646934460888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/exp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(y_test, y_pred))\n",
    "print (classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
